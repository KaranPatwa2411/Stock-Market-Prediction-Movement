# Stock Price Movement Prediction
### CSE 572: Data Mining - Final Project
**Author:** Karan Patwa  
**Institution:** Arizona State University

## üìå Project Overview
Predicting the directional movement of stock prices (UP/DOWN) is a challenging binary classification task due to the low signal-to-noise ratio in financial data. This project evaluates whether complex Deep Learning architectures (Time-Series Transformers, LSTMs) outperform robust Ensemble methods (Random Forest) when applied to daily OHLCV data.

The research progressed through two distinct evolutionary phases to address issues with non-stationarity and data leakage found in initial experiments. The final system implements a **Sector-Specific Modeling** strategy, training independent classifiers for *Tech-Growth*, *Stable-Defensive*, and *Macro-Indices* sectors to capture distinct volatility regimes.

## üöÄ Key Findings
Contrary to the trend of applying Transformers to every sequence problem, this study found that for daily tabular stock data:
* **Best Model:** Sector-Specific **Random Forest** (Weighted Precision: **59.4%**)
* **Observation:** Deep Learning models (LSTM, Transformer) struggled to converge beyond the random baseline (~50-52%), likely due to the sparsity of signal in daily price history compared to the model complexity.
* **Conclusion:** Domain-aware feature engineering (Sector Relative Alpha) combined with ensemble bagging yields superior results to raw deep learning on this specific task.

## üìÇ Repository Structure

This repository is organized into two phases representing the project's evolution.

### **Phase 2: Final System (The Proposed Solution)**
* **`DataFetch_Phase2.py`**: The improved data ingestion script. Fetches 10 years of data for 28 tickers, adjusts for splits/dividends, and enforces strict chronological sorting to prevent look-ahead bias.
* **`Final_Models.ipynb`**: The core analysis notebook.
    * Performs Sector-Specific Feature Engineering.
    * Trains and benchmarks LR, SVM, Random Forest, LSTM, and Time-Series Transformers.
    * Generates final performance metrics and visualizations.
* **`combined_stock_data.csv`**: The clean, raw dataset generated by Phase 2 fetching.

### **Phase 1: Baseline Experiments (Legacy)**
* **`DataFetch.py`**: Initial data scraping script.
* **`DataPreprocessing.ipynb`**: Initial feature engineering (SMA, RSI, MACD) on the aggregate dataset.
* **`models.ipynb`**: Baseline model training (Logistic Regression, SVM) showing initial near-50% performance.
* **`combined_stock_data_with_features.csv`**: The preprocessed dataset from Phase 1.

### **Artifacts**
* `X_train.csv`, `X_test.csv`, `y_train.csv`, `y_test.csv`: The chronological train/test splits used to reproduce results.
* `scaler.pkl`: Saved standard scaler for data normalization.

## üõ†Ô∏è Methodology

### 1. Data Pipeline
Data is sourced via the Yahoo Finance API. The pipeline segments 28 tickers into three clusters:
* **Tech-Growth:** High beta, momentum-driven (e.g., NVDA, TSLA).
* **Stable-Defensive:** Low beta, mean-reverting (e.g., KO, JNJ).
* **Macro-Indices:** Market benchmarks (e.g., ^GSPC).

### 2. Feature Engineering
I extracted 43 technical features, but the critical innovation is **Sector-Relative Alpha**:

$$\text{Rel\\_Return}_{i,t} = R_{i,t} - \frac{1}{|S|} \sum_{j \in S} R_{j,t}$$

This normalizes a stock's movement against its sector, isolating intrinsic strength from broad market noise.

### 3. Model Architecture
I compared:
* **Ensemble:** Random Forest (Bagging, Non-linear).
* **Recurrent:** LSTM (Sequential processing).
* **Attention:** Hugging Face Time Series Transformer (Global context).

## üíª Usage

1.  **Install Dependencies:**
    ```bash
    pip install pandas numpy scikit-learn tensorflow transformers yfinance seaborn matplotlib
    ```

2.  **Run the Pipeline:**
    * Execute `DataFetch_Phase2.py` to refresh data.
    * Open `Final_Models.ipynb` to run the training and evaluation loop.

## üìä Results Summary

| Model | Weighted Precision | Recall | F1-Score |
|-------|-------------------|--------|----------|
| **Random Forest (Proposed)** | **0.594** | 0.233 | 0.333 |
| Support Vector Machine | 0.524 | 0.698 | 0.598 |
| LSTM | 0.519 | 0.547 | 0.532 |
| Time Series Transformer | 0.500 | 0.600 | 0.544 |
| Logistic Regression | 0.515 | 0.844 | 0.639 |

The Random Forest's high precision indicates a "conservative" trading strategy that minimizes false positives, making it the most viable model for real-world application despite lower recall.
